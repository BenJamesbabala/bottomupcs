<chapter id="wk2">
  
  <title>Computer Architecture for Beginners</title>

  <sect1>
    <title>The CPU</title>
    
    <figure>
      <title>The CPU</title>
      <mediaobject>
	<imageobject>
	  <imagedata fileref="wk2/figures/computer.eps" format="EPS">
	</imageobject>
	<imageobject>
	  <imagedata fileref="wk2/figures/computer.png" format="PNG">
	</imageobject>
	<textobject>
	  <phrase>The CPU performs instructions on values held in
	      registers.  This example shows firstly setting the value
	      of R1 to 100, loading the value from memory location
	      0x100 into R2, adding the two values together and
	      placing the result in R3 and finally storing the new
	      value (110) to R4 (for further use). </phrase>
	</textobject>
      </mediaobject>
      
    </figure>
    
    
    <para>To greatly simplify, a computer consists of a central
    processing unit (CPU) attached to memory.  The figure above
    illustrates the general principle behind all computer
    operations.</para>
    
    <para>The CPU executes instructions read from memory.  There are
    two types of instructions</para>
    
    <orderedlist>
      <listitem>
	<para>Those that <emphasis>load</emphasis> and
	<emphasis>store</emphasis> values from memory and to memory,
	respectively.</para>
      </listitem>
      <listitem>
	<para>Those that operatate on values stored in
	registers.</para>
      </listitem>
    </orderedlist>
    
    <para>So in the example we are simply adding 100 to a value stored
    in memory, and storing this new result back into memory.</para>
    
    <sect2>
      <title>Branching</title>
      
      <para>Apart from loading or storing, the other important
	operation of a CPU is <emphasis>branching</emphasis>.
	Internally, the CPU keeps a record of the next instruction to
	be executed in the <emphasis>instruction pointer</emphasis>.
	Usually, the instruction pointer is incremeted to point to the
	next instruction sequentially; the branch instruction will
	usually check if a specific register zero or if a flag is set
	and, if so, will modify the pointer to a different address.
	This is how loops and decision statements
	(i.e. <computeroutput>if</computeroutput> statements) are
	handled by the processor.</para>
      
    </sect2>
    
    <sect2>
      <title>Cycles</title>
      
      <para>We are all familiar with the speed of the computer,
	given in Megahertz or Gigahertz (millions or thousands of
	millions cycles per second).  This is called the
	<emphasis>clock speed</emphasis> since it is the speed that an
	internal clock within the computer pulses.  On each pulse, a
	new instruction is executed.
	</para>
      
    </sect2>
    
    <sect2>
      <title>Fetch, Decode, Execute, Store</title>
      
      <para>Executing an instruction consists of a particular cycle
	of events, particularly fetching, decoding, executing and
	storing.</para>
      
      <para>For example, to do the
	<computeroutput>add</computeroutput> instruction above it must
	be</para>
      
      <orderedlist>
	<listitem>
	  <para>Fetch : that is from memory into the
	    processor.</para>
	</listitem>
	<listitem>
	  <para>Decode : the processor must internally decode what
	    it has to do (in this case add).</para>
	</listitem>
	<listitem>
	  <para>Execute : take the values from the registers,
	    actually add them together</para>
	</listitem>
	<listitem>
	  <para>Store : store the result back into another
	    register.</para>
	</listitem>
      </orderedlist>

      <para>Once upon a time, all of these steps would have taken
	place during one cycle.  However as hardware engineers started
	to increase the clock speed, it became impractical to do all
	those steps in one cycle.</para>

      <para>Internally, the CPU has many different sub components that
	perform each of the above steps, and generally they can all
	happen at the same time.  The CPU can be smart and schedule
	many different parts of different operations all at the same
	time, effectivley doing multiple instructions in the one clock
	cycle.  This is called
	<emphasis>pipelining</emphasis><footnote><para>In fact, any
	modern processor has many more than four stages it can
	pipeline.  The more stages that can be executed at the same
	time, the deeper the pipeline.</para></footnote>, and a
	processor that can do this is refered to as a
	<emphasis>superscalar architecture</emphasis>.  All modern
	processors are superscalar.</para>

      <para>Branch instruction play havoc with this model however,
	since they may or may not cause execution to start from a
	different place.  If you are pipelining, you will have to
	basically guess which way the branch will go, so you know
	which instructions to bring into the pipeline.  If the CPU has
	predicted correctly, everything goes fine! Converslely, if the
	processor has predicted incorrectly it has wasted a lot of
	time and has to clear the pipeline and start again.</para>

    </sect2>

    <sect2>
      <title>CISC v RISC</title>

      <para>A common way to divide computer architectures is into
      <emphasis>Complex Instruction Set Computer</emphasis> (CISC) and
      <emphasis>Reduced Instruction Set Computer</emphasis>
      (RISC).</para>

      <para>Note in the first example, we have explictley loaded
      values into registers, performed an addition and stored the
      result value held in another register back to memory.  This is
      an example of a RISC approach to computing -- only performing
      operations on values in registers and explictley loading and
      storing values to and from memory.
      </para>

      <para>A CISC approach would use only a single instruction taking
      values from memory, performing the addition internally and
      writing the result back.  This means the instruction may take
      many cycles, but ultimately both approaches achieve the same
      goal.</para>

      <para>All modern architectures would be considered RISC
      architectures<footnote><para>Even the most common architecture,
      the Intel Pentium, whilst having an instruction set that is
      categorised as CISC, internally breaks down instructions to RISC
      style sub-instructions inside the chip before
      executing.</footnote>.</para>

      <para>There are a number of reasons for this</para>

      <itemizedlist>
	<listitem>
	  <para>Whilst RISC makes assembly programming becomes more
	  complex, since virtually all programmers use high level
	  languages and leave the hard work of producing assembley
	  code to the compiler, so the other advantages outweigh this
	  disadvantage.</para>
	</listitem>

	<listitem>
	  <para>Because the instructions in a RISC processor are much
	  more simple, there is more space inside the chip for
	  registers.  As we know from the memory hierarchy, registers
	  are the fastest type of memory and ultimatley all
	  instructions must be performed on values held in registers,
	  so all other things being equal more registers leads to
	  higher performance.</para>
	</listitem>

	<listitem>
	  <para>Since all instructions execute in the same time,
	  pipelining is possible.  We know pipelining requires streams
	  of instructions being constantly fed into the processor, so
	  if some instructions take a very long time and others do
	  not, the pipeline becomes far to complex to be
	  effective.</para>
	</listitem>
      </itemizedlist>

    </sect2>

  </sect1>

  <sect1>
    <title>Memory</title>
    
    <sect2>
      <title>Memory Hierarchy</title>
      
      <para>The CPU can only directly fetch instructions and data
	from cache memory, located directly on the processor chip.
	Cache memory must be loaded in from the main system memory
	(the Random Access Memory, or RAM).  RAM however, only retains
	it's contents when the power is on, so needs to be stored on
	more permanent storage.</para>
      
      <para>We call these layers of memory the <emphasis>memory
      hierarchy</emphasis></para>
      
      <table>
	<title>Memory Hierarchy</title>
	<tgroup cols="3">
	  <thead>
	    <row>
	      <entry>Speed</entry>
	      <entry>Memory</entry>
	      <entry>Description</entry>
	    </row>
	  </thead>
	  <tbody>
	    <row>
	      <entry>Fastest</entry>
	      <entry>Cache</entry>
	      <entry>Cache memory is memory actually embedded inside
		the CPU.  Cache memory is very fast, typically taking
		only once cycle to access, but since it is embeded
		directly into the CPU there is a limit to how big it
		can be.  In fact, there are several sub-levels of
		cache memory (termed L1, L2, L3) all with slightly
		increasing speeds.</entry>
	    </row>
	    
	    <row>
	      <entry></entry> 
	      <entry>RAM</entry> 
	      <entry>All instructions and storage addresses for the
		processor must come from RAM.  Although RAM is very
		fast, there is still some significant time taken for
		the CPU to access it (this is termed
		<emphasis>latency</emphasis>). RAM is stored in
		seperate, dedicated chips attached to the motherboard,
		meaning it is much larger than cache memory.
		</entry>
	    </row>

	      <row>
		<entry>Slowest</entry>
		<entry>Disk</entry>
		<entry>We are all familiar with software arriving on a
		floppy disk or CDROM, and saving our files to the hard
		disk.  We are also familiar with the long time a
		program can take to load from the harddisk -- having
		physical mechanisms such as spinning disks and moving
		heads means disks are the slowest form of storage.
		But they are also by far the largest form of
		storage.</entry>
	      </row>
	    </tbody>
	  </tgroup>
	</table>

	<para>The important point to know about the memory heirarchy
	is the trade offs between speed an size -- the faster the
	memory the smaller it is.  Of course, if you can find a way to
	change this equation, you'll end up a billionare!</para>

      </sect2>

    </sect1>

  <sect1>
    <title>The rest</title>

    <sect2>
      <title>Pehperials</title>
      <para>communicate over busses.</para>

      <sect3>
	<title>Interrupts</title>
	<para></para>
      </sect3>

      <sect3>
	<title>DMA</title>
	<para></para>
      </sect3>

    </sect2>

  </sect1>

    <sect1>
      <title>Exercises</title>
      <itemizedlist>
	<listitem>
	  <para>Explain why the clock speed, given in cycles per
	  second, is not the best indicator of acutal processor
	  speed.</para>
	</listitem>
      </itemizedlist>
    </sect1>

</chapter>

<!--
Local Variables:
mode: sgml
sgml-parent-document: ("../csbu.sgml" "book" "chapter")
End:
-->