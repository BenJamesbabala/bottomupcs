<chapter id="chapter05">

  <title>Virtual Memory</title>

  <sect1>
    <title>What Virtual Memory <emphasis>isn't</emphasis></title>

    <para>Virtual memory is often naively discussed as a way to
    extended your RAM by using the hard drive as extra, slower, system
    memory.  That is, once your system runs out of memory, it flows
    over onto the hard drive which is used as "virtual" memory.</para>

    <para>In modern operating systems, this is commonly referred to as
    <emphasis>swap space</emphasis>, because unused parts of memory as
    swapped out to disk to free up main memory (remember, programs can
    only execute from main memory).
    </para>

    <para>Indeed, the ability to swap out memory to disk is an
    important part of how virtual memory works, but as you will see it
    is not the purpose of virtual memory, but rather a very useful
    side effect!</para>

  </sect1>

  <sect1>
    <title>What virtual memory <emphasis>is</emphasis></title>

    <para>Virtual memory is all about making use of <emphasis>address
    space</emphasis>.</para>

    <para>The address space of a processor refers the range of
    possible addresses that it can use when loading and storing to
    memory.  The address space is limited by the width of the
    registers, since as we know to load an address we need to issue a
    <computeroutput>load</computeroutput> instruction with the address
    to load from stored in a register.  For example, registers that
    are 32 bits wide can hold addresses in a register range from
    <computeroutput>0x00000000</computeroutput> to
    <computeroutput>0xFFFFFFF</computeroutput>.
    2^<superscript>32</superscript> is equal to 4GB, so a 32 bit
    processor can load or store to up to 4GB of memory.</para>

    <sect2>
      <title>64 bit computing</title>

      <para>New processors are generally all 64-bit processors, which
    as the name suggests has registers 64 bits wide.  As an exercise,
    you should work out the address space available to these
    processors (hint: it's big!).</para>

      <para>64-bit computing does have some trade-offs against using
      smaller bit-width processors.  Every program compiled in 64-bit
      mode requires 8-byte pointers, which can increase code and data
      size, and hence cache performance.  However, 64-bit processers
      tend to have more registers, which means less need to save
      temporary variables to memory when the compiler is under
      register pressure.</para>

      <sect3>
	<title>Canonical Addresses</title>

	<para>While 64-bit processors have 64-bit wide registers,
	systems generally do not implement all 64-bits for addressing
	&mdash; it is not actually possible to do
	<computeroutput>load</computeroutput> or
	<computeroutput>store</computeroutput> to all 16 exabytes of
	theoretical physical memory!</para>

	<para>Thus most architectures define an
	<emphasis>unimplemented</emphasis> region of the address space
	which the processor will consider invalid for use.  x86-64 and
	Itanium both define the most-significant valid bit of an
	address, which must then be sign-extended (see <xref
	linkend="sign_extension"></xref>) to create a valid address.
	The result of this is that the total address space is
	effectively divided into two parts, an upper and a lower
	portion, with the addresses in-between considered invalid.
	This is illustrated in <xref
	linkend="canonical_address"></xref>.  Valid addresses are
	termed <emphasis>canonical addresses</emphasis> (invalid
	addresses being <emphasis>non</emphasis>-canonical).</para>

      <figure id="canonical_address">
	<title>Illustration of canonical addresses</title>
	<mediaobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/canonical.eps" format="EPS" />
	  </imageobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/canonical.png" format="PNG" />
	  </imageobject>
	  <textobject>
	    <phrase>By defining a most-significant bit that must be
	    sign-extended to create a full address, the address-space
	    is effectively partitioned into upper and lower portions,
	    with intermediate addresses considered invalid by the
	    processor.</phrase>
	  </textobject>
	</mediaobject>
      </figure>

	<para>The exact most-significant bit value for the processor
	can usually be found by querying the processor itself using
	its informational instructions.  Although the exact value is
	implementation dependent, a typical value would be 48;
	providing 2<superscript>48</superscript> = 256 TiB of usable
	address-space.
	</para>

	<para>Reducing the possible address-space like this means that
	significant savings can be made with all parts of the
	addressing logic in the processor and related components, as
	they know they will not need to deal with full 64-bit
	addresses.  Since the implementation defines the upper-bits as
	being signed-extended, this prevents portable operating
	systems using these bits to store or flag additional
	information and ensuring compatibility if the implementation
	wishes to implement more address-space in the future.</para>
      </sect3>

    </sect2>

    <sect2>
      <title>Using the address space</title>

      <para>As with most components of the operating system, virtual
    memory acts as an abstraction between the address space and the
    physical memory available in the system.  This means that when a
    program uses an address that address does not refer to the bits in
    an actual physical location in memory.</para>

    <para>So to this end, we say that all addresses the program uses
      are <emphasis>virtual</emphasis>.  The operating system keeps
      track of virtual addresses and how they are allocated to
      <emphasis>physical</emphasis> addresses.  When a program does a
      load or store from an address, the processor and operating
      system work together to convert this virtual address to the
      actual address in the system memory chips.
      </para>

    </sect2>

  </sect1>

  <sect1>
    <title>Pages</title>

    <para>The total address-space is divided into individual
    <emphasis>pages</emphasis>.  Pages can be many different sizes;
    generally they are around 4KB, but this is not a hard and fast
    rule and they can be much larger.  The page is the smallest unit
    of memory that the operating system and hardware can deal
    with.</para>

    <para>Additionally, each page has a number of attributes set by
    the operating system.  Generally, these include read, write and
    execute permissions for the current page.  For example, the
    operating system can generally mark the code pages of a process
    with an executable flag and the processor can choose to not
    execute any code from pages without this bit set.</para>

    <figure>
      <title>Virtual memory pages</title>
      <mediaobject>
	<imageobject>
	  <imagedata fileref="chapter05/figures/page.eps" format="EPS" />
	</imageobject>
	<imageobject>
	  <imagedata fileref="chapter05/figures/page.png" format="PNG" />
	</imageobject>
	<textobject>
	  <phrase>Pages</phrase>
	</textobject>
      </mediaobject>
    </figure>

  </sect1>

  <sect1>
    <title>Physical Memory</title>

    <para>Just as the operating system divides the possible address
    space up into pages, it divides the available physical memory up
    into <emphasis>frames</emphasis>.</para>

    <para>A frame is just the conventional name for a hunk of physical
    memory the same size as the system page size.</para>

  </sect1>

  <sect1>
    <title>Pages + Frames = Page Tables</title>

    <para>The job of the operating system is to keep track of which
    virtual-page points to which physical frame.  This information is
    kept in a <emphasis>page-table</emphasis> which, in its simplest
    form, could simply be a table where each row contains its
    associated frame.  If you were to use this simple system, with a
    32 bit address space and 4K pages there would be 1048576 possible
    pages to keep track of in the page table
    (2<superscript>32</superscript> &divide; 4096); hence the table
    would be 1048576 entries long to ensure we can always find the
    physical address of any virtual-page.</para>

    <para>Page tables can have many different structures and are
    highly optimised, as the process of finding a page in the page
    table can be a lengthly process.  We will examine page-tables in
    more depth later.</para>

  </sect1>

  <sect1>
    <title>Virtual Addresses</title>

    <para>When a program accesses memory, it does not know or care
    where the physical memory backing the address is stored.  It knows
    it is up to the operating system to map the address to the right
    place and provide it with the data it wants.</para>

    <para>We call the address the userspace program is using to access
    memory a <emphasis>virtual address</emphasis>.  A virtual address
    consists of two parts; the page and an offset into that
    page.</para>

    <sect2>
      <title>Page</title>

      <para>The entire address space is divided up into pages, so each
      possible address must reside within a page.  The page part of
      the virtual address acts as an index into the page table.</para>
    </sect2>

    <sect2>
      <title>Offset</title>

      <para>A page has many bytes of memory inside it, so the last
      bits of the virtual address are called the
      <emphasis>offset</emphasis> which is the location difference
      between the address you want and the start of the page.  You
      require enough bits in the offset to be able to get to any byte
      in the page.  For a 4K page you require (4K == (4 * 1024) ==
      4096 == 2<superscript>12</superscript> ==) 12 bits.  Remember
      that the smallest amount of memory that the operating system or
      hardware deals with is a page, so each of these 4096 addresses
      reside within a single page and are dealt with as "one".</para>

    </sect2>

    <sect2>
      <title>Virtual Address Translation</title>

      <para>Virtual address translation refers to the process of
      finding out which physical page maps to which virtual
      page.</para>

      <para>When the operating system needs to find the actual memory
      behind a virtual address, it only deals with the page component
      of the virtual address (since the smallest amount of memory it
      will deal with is a page).  It takes the page number and looks
      it up in the page table.  This gives a pointer to a physical
      address, to which the offset from the virtual address is added,
      giving the actual location in system memory.  If it doesn't
      exist in the page table then the process is trying to access
      memory that has not been allocated to it by the operating system
      and the access will not be allowed.</para>

      <figure>
	<title>Virtual Address Translation</title>
	<mediaobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/virtaddress.eps" format="EPS" />
	  </imageobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/virtaddress.png" format="PNG" />
	  </imageobject>
	  <textobject>
	    <phrase>Converting a virtual address to a physical address</phrase>
	  </textobject>
	</mediaobject>
      </figure>

      <para>We can follow this through for our previous example of a
      simple <emphasis>linear</emphasis> page table.  We calculated
      that a 32-bit address-space would require a table of 1048576
      entries when using 4KiB pages.  Thus to map a theoretical
      address of 0x80001234, the first step would be to remove the
      offset bits.  In this case, with 4KiB pages, we know we have
      12-bits (2<superscript>12</superscript> == 4096) of offset.  So
      we would right-shift out 12-bits of the virtual address, leaving
      us with 0x80001.  Thus (in decimal) the value in row 524289 of
      the linear page table would be the physical frame corresponding
      to this page.</para>

    </sect2>
  </sect1>

  <sect1>
    <title>Consequences of virtual addresses, pages and page tables</title>

    <para>Virtual addressing, pages and page tables opens up a number
    of interesting opportunities for the operating system.</para>

    <sect2>
      <title>Individual address spaces</title>

      <para>If the operating system gives each process its own page
	table, then every process can pretend that it has access to
	the entire address space available from the processor.  It
	doesn't matter that two processes might use the same address,
	since the page table will map it to a different place in
	physical memory.  Every modern operating system provides each
	process with its own address space like this.</para>

      <para>Over time, physical memory becomes
      <emphasis>fragmented</emphasis>, meaning that there are "holes"
      of free space in the physical memory.  Having to work around
      these holes would be at best annoying and would become a serious
      limit to programmers.  By using assigning a virtual address
      space to each process the programmer can leave working around
      fragmentation up to the operating system.</para>

    </sect2>

    <sect2>
      <title>Protection</title>

      <para>We previously mentioned that the virtual mode of the 386
      processor is called protected mode, and this name arises from
      the protection that virtual memory can offer to processes
      running on it.</para>

      <para>In a system without virtual memory, every process has
      complete access to all of system memory.  This means that there
      is nothing stopping one process from overwriting another
      processes memory, causing it to crash (or perhaps worse, return
      incorrect values, especially if that program is managing your
      bank account!)</para>

      <para>This level of protection is provided because the operating
      system is now the layer of abstraction between the process and
      memory access.  If a process gives a virtual address that is not
      covered by its page table, then the operating system knows that
      that process is doing something wrong and can inform the process
      it has stepped out of its bounds.</para>

      <para>Since each page has extra attributes, a page can be set
      read only, write only or have any number of other interesting
      attributes.  When the process tries to access the page, the
      operating system can check if it has sufficient permissions and
      stop it if it does not (writing to a read only page, for
      example).</para>

      <para>Systems that use virtual memory are inherently more stable
      because, with a well "perfect" operating system, a process can
      only crash its self and not the entire system (of course, humans
      write operating systems and we inevitably overlook bugs that can
      still cause entire systems to crash).</para>

    </sect2>

    <sect2>
      <title>Swap</title>

      <para>We can also now see how the swap memory is implemented.
      If instead of pointing to an area of system memory the page
      pointer can be changed to point to a location on a
      disk.</para>

      <para>When this page is referenced, the operating system needs
      to move it from the disk back into system memory (remember,
      program code can only execute from system memory).  If system
      memory is full, then <emphasis>another</emphasis> page needs to
      be kicked out of system memory and put into the swap disk before
      the required page can be put in memory.  If another process
      wants that page that was just kicked out back again, the process
      repeats.</para>

      <para>This can be a major issue for swap memory.  Loading from
      the hard disk is very slow (compared to operations done in
      memory) and most people will be familiar with sitting in front of
      the computer whilst the hard disk churns and churns whilst the
      system remains unresponsive.</para>

      <sect3>
	<title>mmap</title>

	<para>A different but related process is the memory map, or
	<computeroutput>mmap</computeroutput> (from the system call
	name).  If instead of the page table pointing to physical
	memory or swap the page table points to a file, on disk, we
	say the file is
	<computeroutput>mmap</computeroutput>ed.</para>

	<para>Normally, you need to
	<computeroutput>open</computeroutput> a file on disk to obtain
	a file descriptor, and then
	<computeroutput>read</computeroutput> and
	<computeroutput>write</computeroutput> it in a sequential
	form.  When a file is mmaped it can be accessed just like
	system RAM.  
	</para>

      </sect3>

    </sect2>
  
    <sect2>
      <title>Sharing memory</title>

      <para>Usually, each process gets its own page table, so any
      address it uses is mapped to a unique frame in physical memory.
      But what if the operating system points two page table entries
      to the same frame?  This means that this frame will be shared;
      and any changes that one process makes will be visible to the
      other.</para>

      <para>You can see now how threads are implemented.  Remember
      from previously we said that the Linux
      <computeroutput>clone()</computeroutput> function could share as
      much or as little of a new process with the old process as it
      required.  If a process calls
      <computeroutput>clone()</computeroutput> to create a new
      process, but requests that the two processes share the same page
      table, then you effectively have a <emphasis>thread</emphasis>
      as both processes see the same underlying physical
      memory.</para>

      <para>You can also see now how copy on write is done.  If you
      set the permissions of a page to be read-only, when a process
      tries to write to the page the operating system will be
      notified.  If it knows that this page is a copy-on-write page,
      then it needs to make a new copy of the page in system memory
      and point the page in the page table to this new page.  This can
      then have its attributes updated to have write permissions and
      the process has its own unique copy of the page.</para>

    </sect2>

    <sect2>
      <title>Disk Cache</title>

      <para>In a modern system, it is often the case that rather than
      having too little memory and having to swap memory out, there is
      more memory available than the system is currently using.</para>

      <para>The memory hierarchy tells us that disk access is much
      slower than memory access, so it makes sense to move as much
      data from disk into system memory if possible.</para>

      <para>Linux, and many other systems, will copy data from files
      on disk into memory when they are used.  Even if a program only
      initially requests a small part of the file, it is highly likely
      that as it continues processing it will want to access the rest
      of file.  When the operating system has to read or write to a
      file, it first checks if the file is in it's memory
      cache.</para>

      <para>These pages should be the first to be removed as memory
      pressure in the system increases.</para>

      <sect3>
	<title>Page Cache</title>

	<para>A term you might hear when discussing the kernel is the
	<emphasis>page cache</emphasis>.</para>

	<para>The <emphasis>page cache</emphasis> refers to a list of
      pages the kernel keeps that refer to files on disk.  From above,
      swap page, mmaped pages and disk cache pages all fall into this
      category.  The kernel keeps this list because it needs to be
      able to look them up quickly in response to read and write
      requests XXX: this bit doesn't file?</para>

      </sect3>

    </sect2>

  </sect1>

  <sect1>
    <title>Hardware Support</title>

    <para>So far, we have only mentioned that hardware works with the
    operating system to implement virtual memory.  However we have
    glossed over the details of exactly how this happens.</para>

    <para>Virtual memory is necessarily quite dependent on the
    hardware architecture, and each architecture has its own
    subtleties.  However, there are are a few universal
    elements to virtual memory in hardware.</para>

    <sect2>
      <title>Physical v Virtual Mode</title>

      <para>All processors have some concept of either operating in
      <emphasis>physical</emphasis> or <emphasis>virtual</emphasis>
      mode.  In physical mode, the hardware expects that any address
      will refer to an address in actual system memory.  In virtual
      mode, the hardware knows that addresses will need to be
      translated to find their physical address.</para>

      <para>In many processors, this two modes are simply referred to
      as physical and virtual mode.  Itanium is one such example.  The
      most common processor, the x86, has a lot of baggage from days
      before virtual memory and so the two modes are referred to as
      <emphasis>real</emphasis> and <emphasis>protected</emphasis>
      mode.  The first processor to implement protected mode was the
      386, and even the most modern processors in the x86 family line
      can still do real mode, though it is not used.  In real mode the
      processor implements a form of memory organisation called
      segmentation.</para>

      <sect3>
	<title>Segmentation</title>

	<para>Segmentation is really only interesting as a historical
	note, since virtual memory has made it less relevant.
	Segmentation has a number of drawbacks, not the least of which
	it is very confusing for inexperienced programmers, which
	virtual memory systems were largely invented to get around.
	</para>

	<para>In segmentation there are a number of registers which
	hold an address that is the start of a segment.  The only way
	to get to an address in memory is to specify it as an offset
	from one of these segment registers.  The size of the segment
	(and hence the maximum offset you can specify) is determined
	by the number of bits available to offset from segment base
	register.  In the x86, the maximum offset is 16 bits, or only
	64K<footnote><para>Imagine that the maximum offset was 32
	bits; in this case the entire address space could be accessed
	as an offset from a segment at
	<computeroutput>0x00000000</computeroutput> and you would
	essentially have a flat layout -- but it still isn't as good as
	virtual memory as you will see.  In fact, the only reason it
	is 16 bits is because the original Intel processors were
	limited to this, and the chips maintain backwards
	compatibility.</para></footnote> .  This causes all sorts of
	havoc if one wants to use an address that is more than 64K
	away, which as memory grew into the megabytes (and now
	gigabytes) became more than a slight inconvenience to a complete
	failure.
	</para>

	<figure>
	  <title>Segmentation</title>
	  <mediaobject>
	    <imageobject>
	      <imagedata fileref="chapter05/figures/segmentation.eps" format="EPS" />
	    </imageobject>
	    <imageobject>
	      <imagedata fileref="chapter05/figures/segmentation.png" format="PNG" />
	    </imageobject>
	    <textobject>
	      <phrase>A segmentation problem.  You only have three
	      segment registers, and can only offset a short distance
	      from each segment.  How do you get to another address?
	      You need to manually reorganise the segment registers,
	      which quickly becomes a bottleneck.</phrase>
	    </textobject>
	  </mediaobject>
	</figure>

	<para>In the above figure, there are three segment registers
	which are all pointing to segments.  The maximum offset
	(constrained by the number of bits available) is shown by
	shading.  If the program wants an address outside this range,
	the segment registers must be reconfigured.  This quickly
	becomes a major annoyance.  Virtual memory, on the other hand,
	allows the program to specify any address and the operating
	system and hardware do the hard work of translating to a
	physical address.</para>

      </sect3>

    </sect2>

    <sect2>
      <title>The TLB</title>

      <para>The <emphasis>Translation Lookaside Buffer</emphasis> (or
      TLB for short) is a cache of virtual-page to physical-frame
      translations inside the processor.  The operating system and
      hardware work together to manage the TLB as the system
      runs.</para>

      <sect3>
	<title>Page Faults</title>

	<para>When a virtual address is requested of the hardware; say
	  via a <computeroutput>load</computeroutput> instruction
	  requesting to get some data, the processor looks for the
	  virtual-address to physical-address translation in its TLB.
	  If it has a valid translation it can then combine this with
	  the offset portion to go straight to the physical address
	  and complete the load.</para>

	<para>However, if the processor can <emphasis>not</emphasis>
	find a translation in the TLB, the processor must raise a
	<emphasis>page fault</emphasis>.  This is an interrupt (as
	discussed before) which the operating system must
	handle.</para>

	<para>When the operating system gets a page fault, it needs to
	go through the page table in memory to find the correct
	translation and insert it into the TLB.</para>

	<para> In the case that the operating system can not find a
	translation in the page table, or alternatively if the
	operating system checks the permissions of the page in
	question and the process is not authorised to view it, the
	operating system must kill the process.  If you have ever seen
	a segmentation fault (or a segfault) this is the operating
	system killing a process that has overstepped its
	bounds.</para>

	<para>Should the translation be found, and the TLB currently
	be full, then one translation needs to be removed before
	another can be inserted.  It does not make sense to remove a
	translation that is likely to be used in the future, as you
	will incur the cost of finding the entry in the page tables
	all over again.  TLBs usually use something like a
	<emphasis>Least Recently Used</emphasis> or LRU algorithm,
	where the oldest translation that has not been used is ejected
	in favour of the new one.</para>

	<para>The access can then be tried again, and, all going well,
	should be found in the TLB and translated correctly.</para>

	<sect4>
	  <title>Finding the page table</title>

	  <para>When we say that the operating system finds the
	  translation in the page table, it is logical to ask how the
	  operating system finds the memory that has the page
	  table.</para>

	  <para>The base of the page table will be kept in a register
	  associated with each process.  This is usally called the
	  page table base register or similar.  By taking the address
	  in this register and adding the page number to it, the
	  correct entry can be located.</para>

	</sect4>

      </sect3>

      <sect3>
	<title>Other page related faults</title>

	<para>There are two other important faults that the TLB can
	generally generate which help to mange accessed and dirty
	pages.  Each page generally contains an attribute in the form
	of a single bit which flags if the page has been accessed or
	is dirty.</para>

	<para>An accessed page is simply any page that has been
	accessed.  When a page translation is initially loaded into
	the TLB the page can be marked as having been accessed (else
	why were you loading it in?<footnote><para>Actually, if you
	were loading it in without a pending access this would be
	called <emphasis>speculation</emphasis>, which is where you do
	something with the expectation that it will pay off.  For
	example, if code was reading along memory linearly putting the
	next page translation in the TLB might save time and give a
	performance improvement.</para></footnote>)</para>

	<para>The operating system can periodically go through
	<emphasis>all</emphasis> the pages and clear the accessed bit
	to get an idea of what pages are currently in use.  When
	system memory becomes full and it comes time for the operating
	system to choose pages to be swapped out to disk, obviously
	those pages whose accessed bit has not been reset are the best
	candidates for removal, because they have not been used the
	longest.</para>

	<para>A dirty page is one that has data written to it, and so
	does not match any data already on disk.  For example, if a
	page is loaded in from swap and then written to by a process,
	before it can be moved out of swap it needs to have its on
	disk copy updated.  A page that is clean has had no changes,
	so we do not need the overhead of copying the page back to
	disk.</para>

	<para>Both are similar in that they help the operating system
	to manage pages.  The general concept is that a page has two
	extra bits; the dirty bit and the accessed bit.  When the page
	is put into the TLB, these bits are set to indicate that the
	CPU should raise a fault .</para>

	<para>When a process tries to reference memory, the hardware
	does the usual translation process.  However, it also does an
	extra check to see if the accessed flag is
	<emphasis>not</emphasis> set.  If so, it raises a fault to the
	operating system, which should set the bit and allow the
	process to continue.  Similarly if the hardware detects that
	it is writing to a page that does not have the dirty bit set,
	it will raise a fault for the operating system to mark the
	page as dirty.</para>

      </sect3>

    </sect2>

    <sect2>
      <title>TLB Management</title>

      <para>We can say that the TLB used by the hardware but managed
      by software.  It is up to the operating system to load the TLB
      with correct entries and remove old entries.</para>

      <sect3>
	<title>Flushing the TLB</title>
	
	<para>The process of removing entries from the TLB is called
      <emphasis>flushing</emphasis>.  Updating the TLB is a crucial
      part of maintaining separate address spaces for processes; since
      each process can be using the same virtual address not updating
      the TLB would mean a process might end up overwriting another's
      memory. </para>

	<para> On some processors, every time there is a context
      switch the entire TLB is flushed.  This can be quite expensive,
      since this means the new process will have to go through the
      whole process of taking a page fault, finding the page in the
      page tables and inserting the translation.</para>

	<para>Other processors implement an extra <emphasis>address
	space ID</emphasis> which is also inserted into the TLB
	translation.  This means each address space (usually each
	process, but remember threads want to share the same address
	space) gets its own ID which is stored along with any
	translations in the TLB.  This means that on a context switch
	the TLB does <emphasis>not</emphasis> need to be flushed,
	since the next process will have a different address space ID
	and even if it asks for the same virtual address, the address
	space ID will differ and so the translation to physical page
	will be different.  This scheme reduces flushing and increases
	overall system performance.</para>

      </sect3>

    </sect2>

  </sect1>

  <sect1>
    <title>Linux Specifics</title>

    <para>Although the basic concepts of virtual memory remain
    constant, the specifics of implementations are highly dependent
    on the operating system and hardware.</para>
    
    <sect2>
      <title>Address Space Layout</title>

      <para>Linux divides the available address space up into a shared
      kernel component and private user space addresses.  This means
      that addresses in the kernel port of the address space map to
      the same physical memory for each process, whilst userspace
      addresses are private to the process.  On Linux, the shared
      kernel space is at the very top of the available address space.
      On the most common processor, the 32 bit x86, this split happens
      at the 3GB point.  As 32 bits can map a maximum of 4GB, this
      leaves the top 1GB for the shared kernel region<footnote>
      <para>This is unfortunately an over-simplification, because many
      machines wanted to support more than 4GB per process.
      <emphasis>High memory</emphasis> support allows processors to
      get access to a full 4GB via special
      extensions.</para></footnote>.</para>

      <figure>
	<title>Linux address space layout</title>
	<mediaobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/linux-layout.eps" format="EPS" />
	  </imageobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/linux-layout.png" format="PNG" />
	  </imageobject>
	  <textobject>
	    <phrase>The Linux address space layout.  Note that pages
	    in the userspace address space are private, whilst the
	    kernel pages are shared.</phrase>
	  </textobject>
	</mediaobject>
      </figure>

    </sect2>

    <sect2>
      <title>Three Level Page Table</title>

      <para>There are many different ways for an operating system to
      organise the page tables but Linux chooses to use a
      <emphasis>hierarchical</emphasis> system.</para>

      <para>As the page tables use a heirarchy that is three levels
      deep, the Linux scheme is most commonly referred to as the
      <emphasis>three level page table</emphasis>.  The three level
      page table has proven to be robust choice, although it is not
      without it's criticism.  The details of the virtual memory
      implementation of each processor vary widley meaning that the
      generic page table Linux chooses must be portable and relatively
      generic.</para>

      <para>The concept of the three level page table is not
      difficult.  We already know that a virtual address consists of a
      page number and an offset in the physical memory page.  In a
      three level page table, the virtual address is further split up
      into a number <emphasis>levels</emphasis>.</para>

      <para>Each level is a page table of it's own right; i.e. it maps
      a page number of a physical page.  In a single level page table
      the "level 1" entry would directly map to the physical frame.
      In the multilevel version each of the upper levels gives the
      address of the physical memory frame holding the next lower
      levels page table.</para>


      <figure>
	<title>Linux Three Level Page Table</title>
	<mediaobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/threelevel.eps" format="EPS" />
	  </imageobject>
	  <imageobject>
	    <imagedata fileref="chapter05/figures/threelevel.png" format="PNG" />
	  </imageobject>
	  <textobject>
	    <phrase>A three level page table</phrase>
	  </textobject>
	</mediaobject>
      </figure>

      <para>So a sample reference involves going to the top level page
      table, finding the physical frame that the next level address is
      on, reading that levels table and finding the physical frame
      that the next levels page table lives on, and so on.</para>

      <para>At first, this model seems to be needlessly complex.  The
      main reason this model is implemented is for size
      considerations.  Imagine the theoretical situation of a process
      with only one single page mapped right near the end of it's
      virtual address space.  We said before that the page table entry
      is found as an offset from the page table base register, so the
      page table needs to be a contiguous array in memory.  So the
      single page near the end of the address space requires the
      entire array, which might take up considerable space (many, many
      physical pages of memory).</para>

      <para>In a three level system, the first level is only one
      physical frame of memory.  This maps to a second level, which is
      again only a single frame of memory, and again with the third.
      Consequently, the three level system reduces the number of pages
      required to only a fraction of those required for the single
      level system.</para>

      <para>There are obvious disadvantages to the system.  Looking up
      a single address takes more references, which can be expensive.
      Linux understands that this system may not be appropriate on
      many different types of processor, so each architecture can
      <emphasis>collapse</emphasis> the page table to have less levels
      easily (for example, the most common architecture, the x86, only
      uses a two level system in its implementation).</para>

    </sect2>

  </sect1>

</chapter>

<!--
Local Variables:
mode: sgml
sgml-parent-document: ("../csbu.sgml" "book" "chapter")
End:
-->